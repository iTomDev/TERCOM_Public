# -*- coding: utf-8 -*-
"""road_training_tf_seg_4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cRF_n7JbYPg3v6J8O_fK4LK7S34iAcIM
"""

!pip install segmentation-models
!pip install tensorflow==2.1.0
!pip install keras==2.3.1
!pip install 'h5py==2.10.0' --force-reinstall

# try latest
!pip install tensorflow==2.7.0
!pip install keras==2.8.0

import tensorflow as tf
import segmentation_models as sm
import glob
import cv2
import os
import numpy as np
from matplotlib import pyplot as plt

from segmentation_models import Unet
from segmentation_models.utils import set_trainable

from google.colab import drive
drive.mount('/content/drive')

!unzip -uq "/content/drive/My Drive/RoadImages3.zip" -d "/content/drive/My Drive/RoadImages3"
!unzip -uq "/content/drive/My Drive/RoadLabels.zip" -d "/content/drive/My Drive/RoadLabels"

BACKBONE = 'resnet34'
#BACKBONE = 'mobilenetv2'
#BACKBONE = 'resnet50'
#BACKBONE = 'vgg16'
preprocess_input = sm.get_preprocessing(BACKBONE)

#Resizing images is optional, CNNs are ok with large images
SIZE_X = 256 #Resize images (height  = X, width = Y)
SIZE_Y = 256

# works as greyscale or rgb, but only up to i = 1961, with RoadImages2
# 500, 1000, 1500, 1700, 1961  < breaks @ 1962

#Capture training image info as a list
train_images = []
i = 0
for directory_path in glob.glob("/content/drive/My Drive/RoadImages2"):
#for directory_path in glob.glob("/content/drive/My Drive/TrainImages2"):
    for img_path in glob.glob(os.path.join(directory_path, "*.png")):
        if i < 1024:
          i = i + 1
          #print(img_path)
          img = cv2.imread(img_path, cv2.IMREAD_COLOR)       
          img = cv2.resize(img, (SIZE_Y, SIZE_X))
          #img = tf.cast(img, tf.float32)/255.
          #img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
          train_images.append(img)
          #np.append(train_images, img)
          #train_images(i,img)
#Convert list to array for machine learning processing        
train_images = np.array(train_images)

#Capture mask/label info as a list
train_masks = [] 
i = 0
for directory_path in glob.glob("/content/drive/My Drive/RoadLabels"):
    for mask_path in glob.glob(os.path.join(directory_path, "*.png")):
      if i < 1024:
          i = i + 1
          mask = cv2.imread(mask_path, 0)       
          mask = cv2.resize(mask, (SIZE_Y, SIZE_X))
          #mask = cv2.cvtColor(mask, cv2.COLOR_RGB2BGR)
          mask = tf.cast(mask, tf.float32)/255.
          train_masks.append(mask)
          #train_labels.append(label)
#Convert list to array for machine learning processing          
train_masks = np.array(train_masks)

#Use customary x_train and y_train variables
X = train_images
Y = train_masks
Y = np.expand_dims(Y, axis=3) #May not be necessary.. leftover from previous code 
#Y = tf.squeeze(Y)

from sklearn.model_selection import train_test_split
x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=24)

# preprocess input
# error: make sure the libs are loaded.knwon good: resnet34
x_train = preprocess_input(x_train)
x_val = preprocess_input(x_val)

# define model
model = sm.Unet(BACKBONE, encoder_weights='imagenet')
#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['mse'])
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
#model.compile(optimizer="rmsprop", loss="sparse_categorical_crossentropy")
#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['mse'])
print(model.summary())

history=model.fit(x_train, 
          y_train,
          batch_size=16, 
          epochs=10,
          verbose=1,
          validation_data=(x_val, y_val))

history=model.fit(x_train, 
          y_train,
          batch_size=32, 
          epochs=50,
          verbose=1,
          validation_data=(x_val, y_val))

#accuracy = model.evaluate(x_val, y_val)
#plot the training and validation accuracy and loss at each epoch
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(loss) + 1)
plt.plot(epochs, loss, 'y', label='Training loss')
plt.plot(epochs, val_loss, 'r', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

model.save('membrane.h5')

from tensorflow import keras
model = keras.models.load_model('membrane.h5', compile=False)
#Test on a different image
#READ EXTERNAL IMAGE...
test_img = cv2.imread('/content/drive/My Drive/RoadImages2/1999.png', cv2.IMREAD_COLOR)       
test_img = cv2.resize(test_img, (SIZE_Y, SIZE_X))
#test_img = cv2.cvtColor(test_img, cv2.COLOR_RGB2BGR)
test_img = np.expand_dims(test_img, axis=0)

prediction = model.predict(test_img)

#View and Save segmented image
prediction_image = prediction.reshape(mask.shape)
prediction_image = cv2.resize(prediction_image, (1024, 1024))
plt.imshow(prediction_image, cmap='gray')
plt.imsave('/content/drive/My Drive/RoadResults/test0.jpg', prediction_image, cmap='gray')

def mean_iou(y_true, y_pred):
    prec = []
    for t in np.arange(0.5, 1.0, 0.05):
        y_pred_ = tf.to_int32(y_pred > t)
        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)
        K.get_session().run(tf.local_variables_initializer())
        with tf.control_dependencies([up_opt]):
            score = tf.identity(score)
        prec.append(score)
    return K.mean(K.stack(prec), axis=0)